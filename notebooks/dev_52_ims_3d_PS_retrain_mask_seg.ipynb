{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "%load_ext autoreload\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 10:08:28,651 - numexpr.utils - INFO - Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-06-07 10:08:28,653 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_parent_dir = \"/cmnfs/proj/ORIGINS/data/brain/FreshFrozenBrain/SingleShot/DDA/\"\n",
    "result_base_dir = \"frame0_1830_ssDDA_P064428_Fresh1_5ug_R1_BD5_1_4921_ScanByScan_RTtol0.9_threshold_missabthres0.5_convergence_NoIntercept_pred_mzBinDigits2_imPeakWidth4_deltaMobilityThres80\"\n",
    "\n",
    "peak_data_dir = \"peak_detection_mask_data_rt_full_overlap\"\n",
    "result_dir = os.path.join(result_parent_dir, result_base_dir)\n",
    "\n",
    "peak_selection_spec_dir = \"IMRT_fulloverlap_data_peak_selection_seg_model_1out32_lr0.005_bs256_comboloss_bce1_dice4_focal1_metric_wdice_channel1_0.5\"\n",
    "peak_selection_dir = os.path.join(result_dir, peak_selection_spec_dir)\n",
    "best_model_path = os.path.join(peak_selection_dir, \"bst_model_0.7089.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import torch\n",
    "from torchvision.transforms import Compose\n",
    "from peak_detection_2d.dataset import MultiHDF5_MaskDataset, Mask_Padding, Mask_AddLogChannel, Mask_ToTensor, Mask_LogTransform\n",
    "\n",
    "patience = 10\n",
    "batch_size = 32\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "\n",
    "hdf5_files = [\n",
    "    os.path.join(os.path.join(result_dir, \"peak_detection_mask_data\"), file)\n",
    "    for file in os.listdir(os.path.join(result_dir, \"peak_detection_mask_data\"))\n",
    "    if file.endswith(\".h5\")\n",
    "]\n",
    "\n",
    "# Define transformations (if any)\n",
    "transformation = Compose([Mask_Padding((258, 258)),Mask_AddLogChannel(), Mask_ToTensor()])\n",
    "\n",
    "# Create the dataset\n",
    "dataset = MultiHDF5_MaskDataset(hdf5_files, transforms=transformation)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_val_dataset, test_dataset = dataset.split_dataset(\n",
    "    train_ratio=0.9, seed=random_state\n",
    ")\n",
    "train_dataset, val_dataset = train_val_dataset.split_dataset(\n",
    "    train_ratio=0.9, seed=random_state\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=128, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 10:33:37,160 - root - INFO - Loaded model from /cmnfs/proj/ORIGINS/data/brain/FreshFrozenBrain/SingleShot/DDA/frame0_1830_ssDDA_P064428_Fresh1_5ug_R1_BD5_1_4921_ScanByScan_RTtol0.9_threshold_missabthres0.5_convergence_NoIntercept_pred_mzBinDigits2_imPeakWidth4_deltaMobilityThres80/IMRT_fulloverlap_data_peak_selection_seg_model_1out32_lr0.005_bs256_comboloss_bce1_dice4_focal1_metric_wdice_channel1_0.5/bst_model_0.7089.bin\n",
      "  7%|â–‹         | 58/786 [00:52<10:59,  1.10it/s, learning_rate=0.005, loss=1.8] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRAIN_MODEL:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m---> 27\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_image_as_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m         train_metric \u001b[38;5;241m=\u001b[39m evaluate(train_dataloader, model, metric\u001b[38;5;241m=\u001b[39mper_image_weighted_dice_metric, use_image_for_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice, channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     29\u001b[0m         val_metric \u001b[38;5;241m=\u001b[39m evaluate(val_dataloader, model, metric\u001b[38;5;241m=\u001b[39mper_image_weighted_dice_metric, use_image_for_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, device \u001b[38;5;241m=\u001b[39m device, channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/cmnfs/proj/ORIGINS/protMSD/maxquant/ScanByScan/peak_detection_2d/seg_model.py:59\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(train_loader, model, optimizer, loss_fn, accumulation_steps, device, use_image_as_input)\u001b[0m\n\u001b[1;32m     57\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     58\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 59\u001b[0m     epoch_losses\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mb_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, train_loader\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m     60\u001b[0m     tk0\u001b[38;5;241m.\u001b[39mset_postfix(\n\u001b[1;32m     61\u001b[0m         loss\u001b[38;5;241m=\u001b[39mepoch_losses\u001b[38;5;241m.\u001b[39mavg, learning_rate\u001b[38;5;241m=\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epoch_losses\u001b[38;5;241m.\u001b[39mavg\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from peak_detection_2d.utils import EarlyStopping\n",
    "from peak_detection_2d.loss import per_image_weighted_dice_metric\n",
    "from peak_detection_2d.seg_model import train_one_epoch, evaluate, UNET\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from peak_detection_2d.combo_loss import ComboLoss\n",
    "TRAIN_MODEL = True\n",
    "EVALUATE = True\n",
    "EPOCHS = 20\n",
    "patience = 10\n",
    "initial_lr = 0.005\n",
    "model = UNET(2, 32, 1, padding=1, downhill=4).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr)\n",
    "if best_model_path is not None:\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    logging.info(\"Loaded model from %s\", best_model_path)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, mode=\"max\", factor=0.1, patience=3, min_lr=0.000001\n",
    ")\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = ComboLoss(**{'weights':{'bce':1, 'dice':4, 'focal':1}, \"channel_weights\": [1, 0.5]})\n",
    "es = EarlyStopping(patience=patience, mode=\"max\")\n",
    "train_loss = []\n",
    "metric = {\"train\":[], \"val\":[]}\n",
    "if TRAIN_MODEL:\n",
    "    for epoch in range(EPOCHS):\n",
    "        loss = train_one_epoch(train_dataloader, model, optimizer, criterion, use_image_as_input=True)\n",
    "        train_metric = evaluate(train_dataloader, model, metric=per_image_weighted_dice_metric, use_image_for_metric=True, device=device, channel = 0)\n",
    "        val_metric = evaluate(val_dataloader, model, metric=per_image_weighted_dice_metric, use_image_for_metric=True, device = device, channel = 0)\n",
    "        metric[\"train\"].append(train_metric)\n",
    "        metric[\"val\"].append(val_metric)\n",
    "        train_loss.append(loss)\n",
    "        scheduler.step(val_metric)\n",
    "        print(f\"EPOCH: {epoch}, TRAIN LOSS: {loss}, TRAIN DICE: {train_metric}, VAL DICE: {val_metric}\")\n",
    "        es(\n",
    "            val_metric,\n",
    "            model,\n",
    "            model_path=os.path.join(\n",
    "                result_dir, peak_data_dir, f\"bst_model_{np.round(val_metric,4)}.bin\"\n",
    "            ),\n",
    "        )\n",
    "        best_model = os.path.join(\n",
    "            result_dir, peak_data_dir, f\"bst_model_{np.round(es.best_score,4)}.bin\"\n",
    "        )\n",
    "        if es.early_stop:\n",
    "            print(\"\\n\\n -------------- EARLY STOPPING -------------- \\n\\n\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_idx = ind_all.loc[ind_all[\"ranks\"] == 128620].index[0]\n",
    "# Plot sample predictions\n",
    "plot_sample_predictions(\n",
    "    test_dataset_log,\n",
    "    model=log_trans_model,\n",
    "    sample_indices=[testset_idx],\n",
    "    # n = 10,\n",
    "    save_dir=None,\n",
    "    metric_list=[\"mask_wiou\", \"wdice\", \"dice\"],\n",
    "    use_hint=False,\n",
    "    zoom_in=False,\n",
    "    label=\"mask\",\n",
    "    device=DEVICE,\n",
    "    # save_dir=os.path.join(log_trans_dir, \"sample_predictions_highest_wiou\"),\n",
    ")\n",
    "plot_sample_predictions(\n",
    "    test_dataset,\n",
    "    model=normal_model,\n",
    "    sample_indices=[testset_idx],\n",
    "    # n = 10,\n",
    "    save_dir=None,\n",
    "    metric_list=[\"mask_wiou\", \"wdice\", \"dice\"],\n",
    "    use_hint=False,\n",
    "    zoom_in=False,\n",
    "    label=\"mask\",\n",
    "    device=DEVICE,\n",
    "    # save_dir=os.path.join(log_trans_dir, \"sample_predictions_highest_wiou\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from peak_detection_2d.utils import plot_sample_predictions\n",
    "from peak_detection_2d.loss import per_image_weighted_iou_metric\n",
    "bst_model = UNET(2, 32, 1, padding=1, downhill=4).to(device)\n",
    "checkpoint=torch.load(best_model, map_location=device)\n",
    "bst_model.load_state_dict(checkpoint)\n",
    "ind_avg_wiou, ind_all_wiou_log = evaluate(\n",
    "    model=bst_model,\n",
    "    valid_loader=test_dataloader,\n",
    "    device=device,\n",
    "    metric=per_image_weighted_iou_metric,\n",
    "    save_all_loss=True,\n",
    "    use_image_for_metric=True,\n",
    "    channel = 0\n",
    ")\n",
    "ind_all_wiou_df = pd.DataFrame(ind_all_wiou_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peak_detection_2d.utils import plot_per_image_metric_distr\n",
    "\n",
    "plot_per_image_metric_distr(ind_all_wiou_log[\"losses\"], \"Weighted_IoU\", save_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([0, 2, 2]) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_idx = ind_all_wiou_df.loc[ind_all_wiou_df[\"ranks\"] == 34051].index[0]\n",
    "plot_sample_predictions(\n",
    "    test_dataset,\n",
    "    model=bst_model,\n",
    "    # n=5,\n",
    "    sample_indices=[testset_idx],\n",
    "    metric_list=[\"wdice\", \"mask_wiou\", \"dice\"],\n",
    "    use_hint=False,\n",
    "    save_dir=None,\n",
    "    zoom_in=False,\n",
    "    label=\"mask\",\n",
    "    channel=1\n",
    "    # save_dir=os.path.join(result_dir, peak_data_dir, \"sample_predictions\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "if EVALUATE:\n",
    "    test_score = evaluate(test_dataloader, model, metric=weighted_dice_loss)\n",
    "    print(f\"Valid dice score: {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from peak_detection_2d.loss import WeightedBoundingBoxIoULoss\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from peak_detection_2d.utils import (\n",
    "    plot_sample_predictions,\n",
    "    plot_history,\n",
    ")\n",
    "from peak_detection_2d.dataset import MultiHDF5Dataset, ToTensor, Padding\n",
    "from peak_detection_2d.seg_model import (\n",
    "    UNET,\n",
    "    train_val_step,\n",
    "    train_one_epoch)\n",
    "num_epoch = 1\n",
    "patience = 10\n",
    "inital_lr = 0.001\n",
    "batch_size = 4\n",
    "\n",
    "random_state = 42\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "model = UNET(1, 16, 1, padding=1, downhill=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=inital_lr)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=3, min_lr=0.000001\n",
    ")\n",
    "\n",
    "loss_tracking = {\"train\": [], \"val\": []}\n",
    "iou_tracking = {\"train\": [], \"val\": []}\n",
    "best_loss = float(\"inf\")\n",
    "for epoch in range(num_epoch):\n",
    "    logging.info(\"Epoch %d/%d\", epoch + 1, num_epoch)\n",
    "\n",
    "    training_loss, trainig_iou = train_one_epoch(\n",
    "        train_dataloader, model, loss_fn, optimizer\n",
    "    )\n",
    "    loss_tracking[\"train\"].append(training_loss)\n",
    "    iou_tracking[\"train\"].append(trainig_iou)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        val_loss, val_iou = train_val_step(val_dataloader, model, loss_fn, None)\n",
    "        loss_tracking[\"val\"].append(val_loss)\n",
    "        iou_tracking[\"val\"].append(vala_iou)\n",
    "        if val_loss < best_loss:\n",
    "            logging.info(\"Saving best model\")\n",
    "            torch.save(\n",
    "                model.state_dict(), os.path.join(result_dir, peak_data_dir, \"best_model.pt\")\n",
    "            )\n",
    "            best_loss = val_loss\n",
    "            current_patience = patience\n",
    "        else:\n",
    "            current_patience -= 1\n",
    "            if current_patience == 0:\n",
    "                logging.info(\"Early stopping\")\n",
    "                break\n",
    "        scheduler.step(val_loss)\n",
    "        logging.info(\n",
    "            \"Last learning rate: %s\",\n",
    "            scheduler.get_last_lr(),\n",
    "        )\n",
    "\n",
    "    logging.info(\"Training loss: %.6f, IoU: %.2f\", training_loss, trainig_iou)\n",
    "    logging.info(\"Validation loss: %.6f, IoU: %.6f\", val_loss, val_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample_predictions(\n",
    "    test_dataset,\n",
    "    model=model,\n",
    "    n=10,\n",
    "    save_dir=os.path.join(peak_selection_dir, \"sample_predictions\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peak_detection_2d.utils import plot_data_points\n",
    "\n",
    "# Sample n datapoints from test_dataset\n",
    "n = 5\n",
    "sample_indices = np.random.choice(len(test_dataset), n, replace=False)\n",
    "for i in sample_indices:\n",
    "    image, hint, label = test_dataset[i]\n",
    "    output = model(image.unsqueeze(0).float(), hint.unsqueeze(0).float())\n",
    "    iou = iou_batch(output, label.unsqueeze(0))\n",
    "    to_plot = {\"data\": image[0].cpu(), \"hint_idx\": hint.cpu(), \"bbox\": label.cpu()}\n",
    "    plot_data_points(to_plot, pred_bbox=output[0].cpu().detach().numpy(), zoom_in=True)\n",
    "    plt.title(f\"IoU: {iou:.2f}\")\n",
    "    plt.savefig(f\"sample_{i}.png\", dpi=300)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
